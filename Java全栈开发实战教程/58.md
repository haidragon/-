# 用于方便查看回顾
# http://securitytech.cc/ 的免费文本教程

# [官网](securitytech.cc) 会长期更新工具、产品开发、产品开发教程、商业产品开发。视频教程。

# [本人介绍](http://securitytech.cc/about)

![公众号](https://github.com/haidragon/haidragon/blob/main/gzh.png)

-----

## 日志框架整合：Logback + ELK

在微服务架构和分布式系统中，**日志**的重要性不言而喻。它是我们了解系统运行状态、诊断问题、进行性能分析以及进行安全审计的唯一窗口。然而，当应用程序被拆分为多个独立服务时，传统的将日志打印到本地文件的做法会变得极其低效和复杂：

  * **分散的日志**：每个服务实例都有自己的日志文件，需要登录到不同的服务器才能查看。
  * **难以聚合**：无法方便地在一个地方查看所有服务的关联日志，难以追踪跨服务的请求链路。
  * **检索困难**：大量文本日志难以进行高效的搜索、过滤和分析。
  * **实时性差**：无法实时监控日志中的异常或警告。

为了解决这些挑战，我们需要一个集中式的日志管理解决方案。**ELK Stack**（现在通常指 **Elastic Stack**）与 **Logback** 框架的结合，正是当前业界最主流和强大的集中式日志解决方案之一。

-----

### 1\. ELK Stack 概览

ELK Stack 是一套开源工具的集合，最初指的是 **Elasticsearch**、**Logstash** 和 **Kibana**。后来，Elastic 公司又加入了 **Beats** 系列，形成了功能更强大的 **Elastic Stack**。

  * **Elasticsearch (E)**：

      * 一个分布式、RESTful 风格的搜索和分析引擎，基于 Lucene。
      * 核心功能是**存储、搜索和分析**大规模数据，特别是日志数据。
      * 提供强大的全文搜索、聚合分析、实时数据洞察能力。

  * **Logstash (L)**：

      * 一个服务器端数据处理管道，用于从各种来源**摄取数据、进行转换并将其发送到各种目标**。
      * 在日志场景中，Logstash 负责从日志源收集数据，进行清洗（解析、过滤、转换格式等），然后发送到 Elasticsearch。
      * 可以处理结构化和非结构化数据。

  * **Kibana (K)**：

      * 一个开源的数据可视化和探索工具，与 Elasticsearch 协同工作。
      * 提供强大的**仪表盘和图表**功能，可以直观地展示 Elasticsearch 中的数据。
      * 用于搜索、过滤、分析日志，并构建自定义的可视化报表。

  * **Beats (B)**：

      * 一系列轻量级的单一用途数据采集器，用于将各种类型的数据**从边缘机器传输到 Logstash 或 Elasticsearch**。
      * 常见的 Beats 包括：
          * **Filebeat**：用于收集日志文件。
          * **Metricbeat**：用于收集系统和服务指标。
          * **Packetbeat**：用于收集网络数据。
          * **Heartbeat**：用于服务可用性监控。
      * Beats 通常部署在应用服务器上，资源占用极小，比 Logstash 更加轻量级，是日志收集的首选。

-----

### 2\. Logback 框架

**Logback** 是 SLF4J (Simple Logging Facade for Java) 的一个实现，是 Java 应用程序中最常用的日志框架之一。它由 Log4j 的创始人设计，旨在提供更快的性能、更灵活的配置和更丰富的功能。

#### 2.1 Logback 的主要组件

  * **Logger (记录器)**：实际执行日志记录操作的对象。它们是分层的，支持继承关系。
  * **Appender (输出器)**：决定日志输出到哪里，如控制台、文件、数据库、远程服务器等。
  * **Layout / Encoder (布局器/编码器)**：决定日志的输出格式。Encoder 推荐用于将日志事件编码为字节数组，并写入输出流。

#### 2.2 Logback 的主要优点

  * **高性能**：内部优化，在 I/O 操作、内存使用和同步方面表现出色。
  * **灵活配置**：基于 XML 或 Groovy 的配置文件，支持热加载，无需重启应用。
  * **自动重载**：配置文件修改后可自动重新加载，无需重启应用。
  * **丰富的 Appender**：内置多种 Appender，也支持自定义扩展。
  * **强大的过滤功能**：通过各种过滤器实现日志的细粒度控制。
  * **与 SLF4J 完美集成**：作为 SLF4J 的底层实现，可以轻松切换不同的日志实现。

-----

### 3\. Logback + ELK 整合方案

最常见的 Logback 与 ELK 的整合方案是：

**Spring Boot 应用 (Logback) → Filebeat → Logstash → Elasticsearch → Kibana**

这个流程将应用日志通过 Logback 输出到文件，然后由 Filebeat 实时监控并发送到 Logstash 进行处理，Logstash 进一步处理后发送到 Elasticsearch 存储，最后通过 Kibana 进行可视化分析。

#### 3.1 整合步骤与代码示例

假设你有一个 Spring Boot 应用，我们将配置其 Logback 将日志输出为 JSON 格式，方便 Filebeat 和 Logstash 解析。

**步骤 1: Spring Boot 项目引入 Logback 和 Logstash/JSON 依赖**

Spring Boot 项目默认使用 Logback。为了输出 JSON 格式日志，我们需要引入 `logback-json-encoder` 或 `logstash-logback-encoder`。推荐使用 `logstash-logback-encoder`，它功能更强大。

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>net.logstash.logback</groupId>
        <artifactId>logstash-logback-encoder</artifactId>
        <version>7.4</version> </dependency>
    </dependencies>
```

**步骤 2: 配置 Logback (logback-spring.xml)**

在 `src/main/resources/` 目录下创建 `logback-spring.xml` 文件。这是一个将日志输出到控制台和文件（JSON 格式）的示例。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <springProperty scope="context" name="LOG_FILE_PATH" source="logging.file.path" defaultValue="./logs"/>
    <springProperty scope="context" name="SPRING_APP_NAME" source="spring.application.name" defaultValue="default-app"/>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID}){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr([%X{traceId:-},%X{spanId:-}]){yellow} %m%n%wEx</pattern>
        </encoder>
    </appender>

    <appender name="FILE_JSON" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_FILE_PATH}/${SPRING_APP_NAME}.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${LOG_FILE_PATH}/${SPRING_APP_NAME}-%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>100MB</maxFileSize> </timeBasedFileNamingAndTriggeringPolicy>
            <maxHistory>7</maxHistory> </rollingPolicy>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"app_name":"${SPRING_APP_NAME}"}</customFields> <fieldNames>
                <timestamp>timestamp</timestamp>
                <level>level</level>
                <thread>thread_name</thread>
                <message>message</message>
                <logger>logger_name</logger>
                <stackTrace>stack_trace</stackTrace>
            </fieldNames>
            <includeContext>true</includeContext>
            <includeMdc>true</includeMdc>
            <jsonFactoryContext>
                <writeContext>true</writeContext>
            </jsonFactoryContext>
        </encoder>
    </appender>

    <root level="INFO">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="FILE_JSON"/>
    </root>

    </configuration>
```

**说明**：

  * `springProperty`：允许从 Spring Boot 的 `application.yml`/`properties` 中获取配置，如应用名称和日志路径。
  * `CONSOLE` Appender：用于开发调试，将日志输出到控制台。
  * `FILE_JSON` Appender：
      * 使用 `RollingFileAppender` 实现日志文件的按天和大小滚动。
      * `net.logstash.logback.encoder.LogstashEncoder` 是关键，它将日志事件编码为 JSON 格式。
      * `customFields`：可以添加自定义字段，如 `app_name`，方便在 Kibana 中过滤。
      * `fieldNames`：可以自定义 JSON 字段的名称。
      * `includeMdc`：如果使用 **MDC (Mapped Diagnostic Context)** 传递 Sleuth 的 `traceId` 和 `spanId`，它会自动包含进去。

**步骤 3: Spring Boot 应用配置 (application.yml)**

在 `src/main/resources/application.yml` 中配置应用名称和日志路径。

```yaml
# application.yml
spring:
  application:
    name: my-spring-app # 会被 Logback 配置中的 SPRING_APP_NAME 引用
logging:
  file:
    path: /var/log/my-spring-app # 日志文件输出路径
server:
  port: 8080
```

**步骤 4: 部署 Elasticsearch, Logstash, Kibana (ELK)**

最简单的部署方式是使用 Docker Compose。创建一个 `docker-compose.yml` 文件：

```yaml
# docker-compose.yml (适用于测试环境，生产环境请考虑集群部署)
version: '3.8'

services:
  elasticsearch:
    image: elasticsearch:8.13.0 # 使用最新稳定版，注意与Kibana版本匹配
    container_name: elasticsearch
    environment:
      - xpack.security.enabled=false # 禁用安全，方便测试
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m # 调整ES内存，根据实际情况设置
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data # 持久化数据
    networks:
      - elk-network

  logstash:
    image: logstash:8.13.0 # 与ES版本匹配
    container_name: logstash
    ports:
      - "5044:5044" # Filebeat 默认端口
      - "9600:9600" # Logstash 监控 API 端口
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline # Logstash 配置
    environment:
      - xpack.monitoring.enabled=false # 禁用监控，方便测试
    depends_on:
      - elasticsearch
    networks:
      - elk-network

  kibana:
    image: kibana:8.13.0 # 与ES版本匹配
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200 # 连接ES
      - KIBANA_SYSTEM_PASSWORD=your_password # Kibana系统密码，在没有安全设置ES时可以忽略
    depends_on:
      - elasticsearch
    networks:
      - elk-network

volumes:
  elasticsearch_data:

networks:
  elk-network:
    driver: bridge
```

在 `docker-compose.yml` 同级目录下创建 `logstash/pipeline/logstash.conf`：

```conf
# logstash/pipeline/logstash.conf
input {
  beats {
    port => 5044 # 接收来自 Filebeat 的数据
  }
}

filter {
  json {
    source => "message" # Logback 输出的JSON日志在 Filebeat 传输后，通常在 message 字段中
    target => "log_json" # 将解析后的JSON放到一个新字段，避免覆盖message
    skip_on_invalid_json => true
  }
  # 将解析后的 JSON 字段移动到顶级，方便Elasticsearch映射
  mutate {
    add_field => { "[@metadata][target_index]" => "app-logs-%{+YYYY.MM.dd}" } # 定义索引名称格式
    copy => { "[log_json][app_name]" => "[app_name]" }
    copy => { "[log_json][level]" => "[level]" }
    copy => { "[log_json][thread_name]" => "[thread_name]" }
    copy => { "[log_json][message]" => "[message]" }
    copy => { "[log_json][logger_name]" => "[logger_name]" }
    copy => { "[log_json][timestamp]" => "[@timestamp]" } # 将 Logback 的时间戳作为ES的时间戳
    copy => { "[log_json][stack_trace]" => "[stack_trace]" }
  }
  # 删除原始的 message 和 log_json 字段，保持日志清晰
  mutate {
    remove_field => ["message", "log_json"]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"] # 连接 Elasticsearch
    index => "%{[@metadata][target_index]}" # 使用上面定义的索引名称
    # 如果 Elasticsearch 启用了安全认证，这里需要配置 user 和 password
    # user => "elastic"
    # password => "your_password"
  }
  stdout { codec => rubydebug } # 在控制台打印，方便调试
}
```

**步骤 5: 部署 Filebeat**

Filebeat 通常部署在与 Spring Boot 应用相同的服务器上。

  * **下载 Filebeat**：[https://www.elastic.co/downloads/beats/filebeat](https://www.elastic.co/downloads/beats/filebeat)

  * **配置 Filebeat (filebeat.yml)**：

    ```yaml
    # filebeat.yml
    filebeat.inputs:
      - type: log
        enabled: true
        paths:
          - /var/log/my-spring-app/*.log # 监控你的Spring Boot应用日志路径

    output.logstash:
      hosts: ["logstash:5044"] # Logstash 的地址和端口
      # 如果 Logstash 和 Filebeat 不在同一个 Docker Compose 网络中，
      # hosts 应该配置为 Logstash 所在宿主机的 IP 地址。
      # hosts: ["your_logstash_host_ip:5044"]
    ```

**完整流程**：

1.  **启动 ELK Stack**：在 `docker-compose.yml` 所在目录执行 `docker-compose up -d`。
2.  **构建并运行 Spring Boot 应用**：
      * 打包：`mvn clean package`
      * 运行：`java -jar target/my-spring-app.jar` (确保日志文件输出到 `/var/log/my-spring-app`，或者你配置的其他路径)
      * 或者使用 Docker 运行 Spring Boot 应用，并在 Docker Compose 中加入 Spring Boot 应用服务，将日志目录挂载出来。
3.  **启动 Filebeat**：在 Filebeat 安装目录执行 `./filebeat -e` (Linux) 或 `filebeat.exe -e` (Windows)。

**步骤 6: 在 Kibana 中查看日志**

1.  访问 Kibana UI：`http://localhost:5601`。
2.  首次访问可能需要设置一个索引模式。点击 **Management (管理)** -\> **Stack Management (堆栈管理)** -\> **Index Patterns (索引模式)** -\> **Create index pattern (创建索引模式)**。
3.  输入 `app-logs-*` (与 Logstash 配置中的 `target_index` 匹配)。
4.  选择 `@timestamp` 作为时间字段。
5.  点击 **Create index pattern**。
6.  切换到 **Analytics (分析)** -\> **Discover (发现)** 页面，你就可以看到你的 Spring Boot 应用的 JSON 格式日志了，并且可以进行搜索、过滤和可视化分析。

-----

### 4\. 优势与注意事项

#### 4.1 优势

  * **集中管理**：所有服务日志统一收集、存储和管理。
  * **强大检索**：Elasticsearch 提供全文搜索和结构化查询能力。
  * **可视化分析**：Kibana 直观展示日志趋势、错误率、性能瓶颈等。
  * **实时监控**：可配置告警，及时发现异常。
  * **可扩展性**：ELK Stack 都是分布式组件，易于水平扩展。
  * **降低应用负载**：日志处理工作从应用中解耦，交给独立的日志收集管道。

#### 4.2 注意事项与优化

  * **日志量管理**：大量日志会占用大量存储空间，需要考虑日志的清理策略 (Elasticsearch 的 ILM - Index Lifecycle Management)。
  * **数据结构化**：尽可能输出结构化日志（如 JSON），方便解析和查询。
  * **日志级别**：生产环境合理设置日志级别，避免输出过多调试信息。
  * **异常栈信息**：确保异常栈信息能完整捕获并输出到日志中。
  * **ELK 性能调优**：Elasticsearch 的 JVM 内存、分片数、副本数，Logstash 的管道配置和批处理大小都需要根据实际负载进行调优。
  * **安全性**：生产环境必须启用 Elasticsearch 和 Kibana 的安全认证，使用 TLS/SSL 加密通信。
  * **Trace ID/Span ID 整合**：结合 Sleuth/OpenTelemetry，将 `traceId` 和 `spanId` 打印到日志中，并在 Kibana 中通过这些 ID 追踪跨服务调用链。
  * **Filebeat 的抗压能力**：Filebeat 会在本地记录读取位置，保证断点续传。

-----

### 5\. 总结

将 **Logback** 与 **ELK Stack (Filebeat + Logstash + Elasticsearch + Kibana)** 整合，是构建健壮的分布式系统日志管理体系的强大组合。通过这种方式，你可以：

  * **集中收集**所有微服务的日志。
  * **高效地搜索、过滤和分析**海量日志数据。
  * **实时监控**系统运行状态和异常。
  * **快速定位**分布式系统中的问题。

 